"""

ä½œè€… ä¹å“¥ ğŸš“ å†…å®¹å‡ä»äº’è”ç½‘æ”¶é›†è€Œæ¥ ä»…ä¾›äº¤æµå­¦ä¹ ä½¿ç”¨ ç‰ˆæƒå½’åŸåˆ›è€…æ‰€æœ‰ å¦‚ä¾µçŠ¯äº†æ‚¨çš„æƒç›Š è¯·é€šçŸ¥ä½œè€… å°†åŠæ—¶åˆ é™¤ä¾µæƒå†…å®¹
                    ====================lege====================

"""

import requests
from bs4 import BeautifulSoup
import re
from base.spider import Spider
import sys
import json
import base64
import urllib.parse

sys.path.append('..')

xurl = "https://pze--eephouquoc.chuvvip6m16.xyz"

xurl2 = "https://pze--eephouquoc.chuvvip6m16.xyz/hflvvip"

headerx = {'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) '
                         'AppleWebKit/537.36 (KHTML, like Gecko) Chrome/128.0.0.0 Safari/537.36'}

pm = ''


class Spider(Spider):
    global xurl
    global headerx

    def getName(self):
        return "é¦–é¡µ"

    def init(self, extend):
        pass

    def isVideoFormat(self, url):
        pass

    def manualVideoCheck(self):
        pass

    def extract_middle_text(self, text, start_str, end_str, pl, start_index1: str = '', end_index2: str = ''):
        if pl == 3:
            plx = []
            while True:
                start_index = text.find(start_str)
                if start_index == -1:
                    break
                end_index = text.find(end_str, start_index + len(start_str))
                if end_index == -1:
                    break
                middle_text = text[start_index + len(start_str):end_index]
                plx.append(middle_text)
                text = text.replace(start_str + middle_text + end_str, '')
            if len(plx) > 0:
                purl = ''
                for i in range(len(plx)):
                    matches = re.findall(start_index1, plx[i])
                    output = ""
                    for match in matches:
                        match3 = re.search(r'(?:^|[^0-9])(\d+)(?:[^0-9]|$)', match[1])
                        if match3:
                            number = match3.group(1)
                        else:
                            number = 0
                        if 'http' not in match[0]:
                            output += f"#{'ğŸ“½ï¸ä¹å“¥ğŸ‘‰' + match[1]}${number}{xurl}{match[0]}"
                        else:
                            output += f"#{'ğŸ“½ï¸ä¹å“¥ğŸ‘‰' + match[1]}${number}{match[0]}"
                    output = output[1:]
                    purl = purl + output + "$$$"
                purl = purl[:-3]
                return purl
            else:
                return ""
        else:
            start_index = text.find(start_str)
            if start_index == -1:
                return ""
            end_index = text.find(end_str, start_index + len(start_str))
            if end_index == -1:
                return ""

        if pl == 0:
            middle_text = text[start_index + len(start_str):end_index]
            return middle_text.replace("\\", "")

        if pl == 1:
            middle_text = text[start_index + len(start_str):end_index]
            matches = re.findall(start_index1, middle_text)
            if matches:
                jg = ' '.join(matches)
                return jg

        if pl == 2:
            middle_text = text[start_index + len(start_str):end_index]
            matches = re.findall(start_index1, middle_text)
            if matches:
                new_list = [f'âœ¨ä¹å“¥ğŸ‘‰{item}' for item in matches]
                jg = '$$$'.join(new_list)
                return jg

    def homeContent(self, filter):
        result = {}
        result = {"class": [{"type_id": "1", "type_name": "ä¹å“¥è§£è¯´ğŸŒ "},
                            {"type_id": "3", "type_name": "ä¹å“¥ä¸­æ–‡ğŸŒ "},
                            {"type_id": "4", "type_name": "ä¹å“¥ä¼ åª’ğŸŒ "},
                            {"type_id": "20", "type_name": "ä¹å“¥æœ‰ç ğŸŒ "},
                            {"type_id": "21", "type_name": "ä¹å“¥æ— ç ğŸŒ "},
                            {"type_id": "22", "type_name": "ä¹å“¥æ¬§ç¾ğŸŒ "},
                            {"type_id": "23", "type_name": "ä¹å“¥ç´ äººğŸŒ "},
                            {"type_id": "24", "type_name": "ä¹å“¥ä¹±ä¼¦ğŸŒ "},
                            {"type_id": "47", "type_name": "ä¹å“¥å›½äº§ğŸŒ "},
                            {"type_id": "29", "type_name": "ä¹å“¥ç½‘çº¢ğŸŒ "},
                            {"type_id": "26", "type_name": "ä¹å“¥ä¸»æ’­ğŸŒ "},
                            {"type_id": "28", "type_name": "ä¹å“¥ä¸‰çº§ğŸŒ "},
                            {"type_id": "30", "type_name": "ä¹å“¥æ¢è„¸ğŸŒ "},
                            {"type_id": "31", "type_name": "ä¹å“¥æŠ–é˜´ğŸŒ "},
                            {"type_id": "75", "type_name": "ä¹å“¥SWAGğŸŒ "},
                            {"type_id": "27", "type_name": "ä¹å“¥ä¸è¢œğŸŒ "},
                            {"type_id": "52", "type_name": "ä¹å“¥åŠ¨æ¼«ğŸŒ "},
                            {"type_id": "25", "type_name": "ä¹å“¥åˆ¶æœğŸŒ "},
                            {"type_id": "54", "type_name": "ä¹å“¥è°ƒæ•™ğŸŒ "},
                            {"type_id": "55", "type_name": "ä¹å“¥ä¸»æ’­ğŸŒ "},
                            {"type_id": "56", "type_name": "ä¹å“¥ç¾ä¹³ğŸŒ "},
                            {"type_id": "58", "type_name": "ä¹å“¥äººå¦»ğŸŒ "},
                            {"type_id": "60", "type_name": "ä¹å“¥å·æ‹ğŸŒ "},
                            {"type_id": "62", "type_name": "ä¹å“¥æ˜æ˜ŸğŸŒ "},
                            {"type_id": "84", "type_name": "ä¹å“¥ç²¾é€‰ğŸŒ "},
                            {"type_id": "80", "type_name": "ä¹å“¥æ¢èŠ±ğŸŒ "},
                            {"type_id": "78", "type_name": "ä¹å“¥ç½‘çº¢ğŸŒ "},
                            {"type_id": "77", "type_name": "ä¹å“¥cosplayğŸŒ "},
                            {"type_id": "82", "type_name": "ä¹å“¥äº‹ä»¶ğŸŒ "},
                            {"type_id": "79", "type_name": "ä¹å“¥ç½‘çˆ†ğŸŒ "},
                            {"type_id": "81", "type_name": "ä¹å“¥èè‰ğŸŒ "},
                            {"type_id": "83", "type_name": "ä¹å“¥å¥³ä¼˜ğŸŒ "}],

                  "list": [],
                  "filters": {"1": [{"key": "å¹´ä»£",
                                     "name": "å¹´ä»£",
                                     "value": [{"n": "å…¨éƒ¨", "v": ""},
                                               {"n": "2018", "v": "2018"}]}],
                              "2": [{"key": "å¹´ä»£",
                                     "name": "å¹´ä»£",
                                     "value": [{"n": "å…¨éƒ¨", "v": ""},
                                               {"n": "2018", "v": "2018"}]}],
                              "3": [{"key": "å¹´ä»£",
                                     "name": "å¹´ä»£",
                                     "value": [{"n": "å…¨éƒ¨", "v": ""},
                                               {"n": "2018", "v": "2018"}]}],
                              "4": [{"key": "å¹´ä»£",
                                     "name": "å¹´ä»£",
                                     "value": [{"n": "å…¨éƒ¨", "v": ""},
                                               {"n": "2018", "v": "2018"}]}]}}

        return result

    def homeVideoContent(self):
        videos = []
        try:
            detail = requests.get(url=xurl2, headers=headerx)
            detail.encoding = "utf-8"
            res = detail.text
            doc = BeautifulSoup(res, "lxml")

            soups = doc.find_all('ul', class_="thumbnail-group")

            for soup in soups:
                vods = soup.find_all('li')

                for vod in vods:
                    names = vod.find('div', class_="video-info")
                    name = names.find('h5').text

                    id = vod.find('a')['href']

                    pic = vod.find('img')['data-original']

                    video = {
                        "vod_id": id,
                        "vod_name": 'ä¹å“¥ğŸ“½ï¸' + name,
                        "vod_pic": pic
                             }
                    videos.append(video)

            result = {'list': videos}
            return result
        except:
            pass

    def categoryContent(self, cid, pg, filter, ext):
        result = {}
        if pg:
            page = int(pg)
        else:
            page = 1
        page = int(pg)
        videos = []

        if 'å¹´ä»£' in ext.keys():
            NdType = ext['å¹´ä»£']
        else:
            NdType = ''

        if page == '1':
            url = f'{xurl}/vodtype/{cid}/'

        else:
            url = f'{xurl}/vodtype/{cid}-{str(page)}/'

        try:
            detail = requests.get(url=url, headers=headerx)
            detail.encoding = "utf-8"
            res = detail.text
            doc = BeautifulSoup(res, "lxml")

            soups = doc.find_all('ul', class_="thumbnail-group")

            for soup in soups:
                vods = soup.find_all('li')

                for vod in vods:
                    names = vod.find('div', class_="video-info")
                    name = names.find('h5').text

                    id = vod.find('a')['href']

                    pic = vod.find('img')['data-original']

                    video = {
                        "vod_id": id,
                        "vod_name": 'ä¹å“¥ğŸ“½ï¸' + name,
                        "vod_pic": pic
                            }
                    videos.append(video)

        except:
            pass
        result = {'list': videos}
        result['page'] = pg
        result['pagecount'] = 9999
        result['limit'] = 90
        result['total'] = 999999
        return result

    def detailContent(self, ids):
        global pm
        did = ids[0]
        result = {}
        videos = []
        playurl = ''
        if 'http' not in did:
            did = xurl + did
        res1 = requests.get(url=did, headers=headerx)
        res1.encoding = "utf-8"
        res = res1.text

        encoded_string = self.extract_middle_text(res,'<li><label>&#26469;&#28304;: </label>','</li>', 0)
        import html
        content = html.unescape(encoded_string)
        content = content.replace('å›½äº§é«˜æ¸…æ— ç -å…è´¹ç¦åˆ©è§†é¢‘åˆ†äº«å¤§å…¨', 'ä¹å“¥çš„æˆå°±ï¼Œå¦‚åŒä¸€éƒ¨æ³¢æ¾œå£®é˜”çš„å²è¯—ï¼Œè®©äººå¿ƒæ½®æ¾æ¹ƒã€‚åœ¨ç’€ç’¨çš„èšå…‰ç¯ä¸‹ï¼Œä»–ç»ˆäºç«™åœ¨äº†èˆå°çš„ä¸­å¤®ï¼Œæˆä¸ºäº†é‚£é¢—æœ€è€€çœ¼çš„æ˜Ÿã€‚ä»–çš„æˆåŠŸï¼Œä¸ä»…ä»…æ˜¯å› ä¸ºä»–çš„å¤©èµ‹å¼‚ç¦€ï¼Œæ›´æ˜¯å› ä¸ºä»–ä¸æ‡ˆçš„åŠªåŠ›å’ŒåšæŒã€‚ä»è´«è‹¦çš„å‡ºèº«åˆ°ä»Šæ—¥çš„è¾‰ç…Œï¼Œä¹å“¥çš„æ¯ä¸€æ­¥éƒ½å……æ»¡äº†è‰°è¾›ã€‚ä»–çš„ç«¥å¹´ï¼Œæ²¡æœ‰å¥¢åçš„ç©å…·ï¼Œæ²¡æœ‰èˆ’é€‚çš„ç¯å¢ƒï¼Œæœ‰çš„åªæ˜¯å¯¹æ¢¦æƒ³çš„æ‰§ç€è¿½æ±‚ã€‚åœ¨é‚£äº›è‰°éš¾çš„æ—¥å­é‡Œï¼Œä»–ä»¥åšéŸ§ä¸æ‹”çš„æ„å¿—ï¼Œä¸€éåˆä¸€éåœ°ç£¨ç»ƒè‡ªå·±çš„æ¼”æŠ€ã€‚ä»–æ¬£èµäº†æ— æ•°å‰è¾ˆçš„å½±ç‰‡ï¼Œä»æ¯ä¸€ä¸ªè§’è‰²ã€æ¯ä¸€åœºæˆä¸­æ±²å–çµæ„Ÿï¼Œä¸æ–­å­¦ä¹ ï¼Œä¸æ–­è¿›æ­¥ã€‚ä¹å“¥çš„å¥‹æ–—å²ï¼Œæ˜¯ä¸€éƒ¨å……æ»¡æ±—æ°´ä¸æ³ªæ°´çš„åŠ±å¿—ç¯‡ç« ã€‚ä»–çš„æˆåŠŸï¼Œæ˜¯å¯¹æ‰€æœ‰è¿½æ¢¦äººçš„æœ€å¥½å¯ç¤ºï¼šæ— è®ºå‡ºèº«å¦‚ä½•ï¼Œåªè¦æœ‰è¶³å¤Ÿçš„åŠªåŠ›å’ŒåšæŒï¼Œæ¢¦æƒ³æ€»æœ‰å®ç°çš„ä¸€å¤©ã€‚ä»–çš„æˆå°±ï¼Œä¸ä»…ä»…æ˜¯ä¸ªäººçš„è£è€€ï¼Œæ›´æ˜¯å¯¹æ‰€æœ‰åšæŒä¸æ‡ˆã€åŠªåŠ›å¥‹æ–—çš„äººçš„é¼“èˆã€‚ä»Šå¤©ï¼Œæˆ‘ä»¬ä¸ºä¹å“¥æ¬¢å‘¼ï¼Œä¸ºä»–çš„æˆåŠŸå–å½©ã€‚ä»–çš„æˆåŠŸï¼Œä¸ä»…ä»…æ˜¯å› ä¸ºä»–çš„æ‰åï¼Œæ›´æ˜¯å› ä¸ºä»–çš„å‹¤å¥‹å’Œæ¯…åŠ›ã€‚ä»–çš„æ•…äº‹å‘Šè¯‰æˆ‘ä»¬ï¼ŒæˆåŠŸä»æ¥ä¸æ˜¯å¶ç„¶ï¼Œè€Œæ˜¯æ— æ•°æ¬¡åŠªåŠ›å’ŒåšæŒçš„ç»“æœã€‚ä¹å“¥çš„ä»Šå¤©ï¼Œæ˜¯å¯¹ä»–è¿‡å»æ‰€æœ‰åŠªåŠ›çš„æœ€å¥½å›æŠ¥ã€‚æˆ‘ä»¬æœŸå¾…ä¹å“¥åœ¨æœªæ¥çš„æ—¥å­é‡Œï¼Œèƒ½å¤Ÿç»§ç»­ä»¥ä»–çš„æ‰åå’ŒåŠªåŠ›ï¼Œä¸ºæˆ‘ä»¬å¸¦æ¥æ›´å¤šä¼˜ç§€çš„ä½œå“ã€‚ä»–çš„æ•…äº‹ï¼Œå°†ç»§ç»­æ¿€åŠ±ç€æ¯ä¸€ä¸ªæœ‰æ¢¦æƒ³çš„äººï¼Œå»è¿½é€ï¼Œå»å®ç°ã€‚è®©æˆ‘ä»¬ä¸ºä¹å“¥çš„æˆå°±é¼“æŒï¼Œä¸ºä»–çš„æœªæ¥ç¥ç¦ï¼ŒæœŸå¾…ä»–åœ¨æœªæ¥çš„æ—¥å­é‡Œï¼Œèƒ½å¤Ÿç»§ç»­å‘å…‰å‘çƒ­ï¼Œæˆä¸ºæ›´å¤šäººå¿ƒä¸­çš„æ˜æ˜Ÿã€‚')
        content = 'ğŸ˜¸ä¹å“¥ğŸ‰ä¸ºæ‚¨ä»‹ç»å‰§æƒ…ğŸ“¢' + content

        encoded_string = self.extract_middle_text(res, '<li class="active"><a>','</a>',0, )
        import html
        xianlu = html.unescape(encoded_string)
        xianlu = xianlu.replace('HDåœ¨çº¿ç‚¹æ’­åœ°å€', 'ğŸ˜¸ä¹å“¥ä¸“çº¿')

        bofang = self.extract_middle_text(res, '<ul class="detail-play-list clearfix', '</ul>', 3,'href="(.*?)" class=".*?" style=".*?">(.*?)</a>')
        bofang = bofang.replace('åœ¨çº¿æ’­æ”¾', 'æ€§ç¦ä¸€ç”Ÿ')
        
        videos.append({
            "vod_id": did,
            "vod_actor": 'ğŸ˜¸ä¹å“¥ ğŸ˜¸æŸå¥³éƒ',
            "vod_director": 'ğŸ˜¸ä¹å“¥',
            "vod_content": content,
            "vod_play_from": xianlu,
            "vod_play_url": bofang
                     })

        result['list'] = videos
        return result

    def playerContent(self, flag, id, vipFlags):  
        parts = id.split("http")
        xiutan = 0
        if xiutan == 0:
            if len(parts) > 1:
                before_https, after_https = parts[0], 'http' + parts[1]
            res = requests.get(url=after_https, headers=headerx)
            res = res.text

            url = self.extract_middle_text(res, '"","url":"', '"', 0).replace('\\', '')


            result = {}
            result["parse"] = xiutan
            result["playUrl"] = ''
            result["url"] = url
            result["header"] = headerx
            return result

    def searchContent(self, key, quick):
        return self.searchContentPage(key, quick, '1')

    def localProxy(self, params):
        if params['type'] == "m3u8":
            return self.proxyM3u8(params)
        elif params['type'] == "media":
            return self.proxyMedia(params)
        elif params['type'] == "ts":
            return self.proxyTs(params)
        return None



